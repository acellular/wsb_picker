{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a262286-a00c-4f31-ab57-2b08fa1fc897",
   "metadata": {},
   "source": [
    "### wsb_picker sample usage\n",
    "Conclusion: I learned some web crawling and machine learning, but if you've somehow ended up here from Google looking for a way to crawl Reddit for stock picks, this might help you learn basic crawling, but DO NOT USE THIS MODEL'S PREDICTIONS, it needs better data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae1d0bab-1043-4348-81b2-8ff503231214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnum_days_back = 2\\nurl = 'https://www.reddit.com/r/wallstreetbets/search/?q=flair%3A%22Daily%20Discussion%22&restrict_sr=1&sort=new'\\nthreads = ThreadsFinder.pull_threads(thread_type, url, num_days_back, skip_first_days=1)\\nwsb.download_comments(threads, comm_limit=2000)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "import wsbCrawler as wsb\n",
    "import ThreadsFinder\n",
    "import PrintToCSV\n",
    "\n",
    "thread_type = 'What'\n",
    "#Download recent comments (if wanted), will otherwise use sample comments included\n",
    "#NOTE: WILL TRY TO OPEN A CROME BROWSER WINDOW WITH CHROMIUM\n",
    "\"\"\"\n",
    "num_days_back = 2\n",
    "url = 'https://www.reddit.com/r/wallstreetbets/search/?q=flair%3A%22Daily%20Discussion%22&restrict_sr=1&sort=new'\n",
    "threads = ThreadsFinder.pull_threads(thread_type, url, num_days_back, skip_first_days=1)\n",
    "wsb.download_comments(threads, comm_limit=2000)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0809360c-d36b-4d08-ba3b-7ce7dd4ff7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON comment files imported:  ['.\\\\comments\\\\q249th.json', '.\\\\comments\\\\q87iwg.json', '.\\\\comments\\\\qa6f3y.json', '.\\\\comments\\\\qaupdv.json', '.\\\\comments\\\\qbjku7.json', '.\\\\comments\\\\qc9j00.json', '.\\\\comments\\\\qd038x.json', '.\\\\comments\\\\qezvzm.json', '.\\\\comments\\\\qfp08o.json', '.\\\\comments\\\\qgete2.json']\n",
      "Number of comments imported: 13080, for thread starting at time: 1635278425\n",
      "Number of comments imported: 11858, for thread starting at time: 1635192017\n",
      "Number of comments imported: 8190, for thread starting at time: 1635105643\n",
      "Number of comments imported: 14728, for thread starting at time: 1634846426\n",
      "Number of comments imported: 9126, for thread starting at time: 1634760025\n",
      "Number of comments imported: 10569, for thread starting at time: 1634673633\n",
      "Number of comments imported: 8611, for thread starting at time: 1634587225\n",
      "Number of comments imported: 7377, for thread starting at time: 1634500840\n",
      "Number of comments imported: 11376, for thread starting at time: 1634241627\n",
      "Number of comments imported: 12559, for thread starting at time: 1633464025\n",
      "Top words counted\n"
     ]
    }
   ],
   "source": [
    "#LOAD IN COMMENTS\n",
    "comments_by_date, num_threads = wsb.pull_comments_from_json(verbose=False)\n",
    "\n",
    "#WORDS TO COUNT\n",
    "words = wsb.pull_words_top(comments_by_date, num_words=1000)\n",
    "#print (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce399a0-dd1a-4eb5-abc2-cb02cf3504bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock history range needed: 2021-10-05 to 2021-10-27\n",
      "DAY:  2021-10-26\n",
      "Stocks counted\n",
      "- RBC: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-27' STOCK:  RBC\n",
      "- SC: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-27' STOCK:  SC\n",
      "- TDA: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-27' STOCK:  TDA\n",
      "- AGC: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-27' STOCK:  AGC\n",
      "- APR: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-27' STOCK:  APR\n",
      "- BRPMW: No data found for this date range, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-27' STOCK:  BRPMW\n",
      "- DCRCW: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-27' STOCK:  DCRCW\n",
      "- VIAC: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-27' STOCK:  VIAC\n",
      "- XLNX: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-27' STOCK:  XLNX\n",
      "Stock change and indicators added.\n",
      "DAY:  2021-10-25\n",
      "Stocks counted\n",
      "- CCIV: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-26' STOCK:  CCIV\n",
      "- DVD: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-26' STOCK:  DVD\n",
      "- INFO: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-26' STOCK:  INFO\n",
      "problem getting stock data out: '2021-10-26' STOCK:  RBC\n",
      "- ROT: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-26' STOCK:  ROT\n",
      "problem getting stock data out: '2021-10-26' STOCK:  TDA\n",
      "- SYMBOL: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-26' STOCK:  Symbol\n",
      "problem getting stock data out: '2021-10-26' STOCK:  AGC\n",
      "- NAKD: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-26' STOCK:  NAKD\n",
      "problem getting stock data out: '2021-10-26' STOCK:  VIAC\n",
      "- VIH: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-26' STOCK:  VIH\n",
      "Stock change and indicators added.\n",
      "DAY:  2021-10-24\n",
      "Stocks counted\n",
      "problem getting stock data out: '2021-10-25' STOCK:  TDA\n",
      "problem getting stock data out: '2021-10-25' STOCK:  APR\n",
      "problem getting stock data out: '2021-10-25' STOCK:  VIAC\n",
      "Stock change and indicators added.\n",
      "DAY:  2021-10-21\n",
      "Stocks counted\n",
      "- HRC: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-22' STOCK:  HRC\n",
      "problem getting stock data out: '2021-10-22' STOCK:  RBC\n",
      "problem getting stock data out: '2021-10-22' STOCK:  TDA\n",
      "problem getting stock data out: '2021-10-22' STOCK:  OLD\n",
      "problem getting stock data out: '2021-10-22' STOCK:  VIAC\n",
      "problem getting stock data out: '2021-10-22' STOCK:  XLNX\n",
      "Stock change and indicators added.\n",
      "DAY:  2021-10-20\n",
      "Stocks counted\n",
      "problem getting stock data out: '2021-10-21' STOCK:  TDA\n",
      "problem getting stock data out: '2021-10-21' STOCK:  VIAC\n",
      "Stock change and indicators added.\n",
      "DAY:  2021-10-19\n",
      "Stocks counted\n",
      "problem getting stock data out: '2021-10-20' STOCK:  DVD\n",
      "- DISCA: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-20' STOCK:  DISCA\n",
      "- FEYE: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-20' STOCK:  FEYE\n",
      "- STMP: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-20' STOCK:  STMP\n",
      "problem getting stock data out: '2021-10-20' STOCK:  XLNX\n",
      "Stock change and indicators added.\n",
      "DAY:  2021-10-18\n",
      "Stocks counted\n",
      "problem getting stock data out: '2021-10-19' STOCK:  DVD\n",
      "problem getting stock data out: '2021-10-19' STOCK:  SC\n",
      "problem getting stock data out: '2021-10-19' STOCK:  Symbol\n",
      "- CORE: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-19' STOCK:  CORE\n",
      "- NETE: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-19' STOCK:  NETE\n",
      "problem getting stock data out: '2021-10-19' STOCK:  VIAC\n",
      "Stock change and indicators added.\n",
      "DAY:  2021-10-17\n",
      "Stocks counted\n",
      "problem getting stock data out: '2021-10-18' STOCK:  AGC\n",
      "problem getting stock data out: '2021-10-18' STOCK:  APR\n",
      "- JCS: No data found, symbol may be delisted\n",
      "problem getting stock data out: '2021-10-18' STOCK:  JCS\n",
      "problem getting stock data out: '2021-10-18' STOCK:  NAKD\n",
      "problem getting stock data out: '2021-10-18' STOCK:  VIAC\n",
      "Stock change and indicators added.\n",
      "DAY:  2021-10-14\n",
      "Stocks counted\n",
      "problem getting stock data out: '2021-10-15' STOCK:  DVD\n",
      "problem getting stock data out: '2021-10-15' STOCK:  TDA\n",
      "problem getting stock data out: '2021-10-15' STOCK:  AGC\n",
      "problem getting stock data out: '2021-10-15' STOCK:  VIH\n",
      "problem getting stock data out: '2021-10-15' STOCK:  XLNX\n",
      "Stock change and indicators added.\n",
      "DAY:  2021-10-05\n",
      "Stocks counted\n",
      "problem getting stock data out: '2021-10-06' STOCK:  TDA\n",
      "problem getting stock data out: '2021-10-06' STOCK:  VIAC\n",
      "problem getting stock data out: '2021-10-06' STOCK:  XLNX\n",
      "Stock change and indicators added.\n",
      "Printed word_counts_stocks_indicators_plus_sentiment to csv\n"
     ]
    }
   ],
   "source": [
    "#get daily returns and indicators on mentioned stocks\n",
    "stocks_data, indicators = wsb.merge_returns_counts_and_indicators(comments_by_date, words, short=False, verbose=False)\n",
    "\n",
    "#name the CSV file\n",
    "lastday = date.fromtimestamp(comments_by_date[0][0])\n",
    "firstday = date.fromtimestamp(comments_by_date[len(comments_by_date)-1][0])\n",
    "csv_file = f'counts_{thread_type}--from{firstday}_to_{lastday}.csv'\n",
    "\n",
    "PrintToCSV.counts_organized(csv_file, stocks_data, words, indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b162de4-d3fe-495d-a4ea-6eade8e8d1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RND SEED: 7544\n",
      "Data shape:  (7174, 1018)\n",
      "Cateorized y: [1 4 6 ... 6 0 3]\n",
      "scaled\n",
      "Log regress start\n",
      "Log regress, split data, complete, score: 0.22909698996655517\n",
      "Data shape:  (1040, 1018)\n",
      "Cateorized y: [3 2 3 ... 1 1 1]\n",
      "scaled\n",
      "LOG PREDICTIONS FINAL\n",
      "SCORE::::  0.24711538461538463\n"
     ]
    }
   ],
   "source": [
    "#MAKE PREDICTIONS!\n",
    "import Predictor as p\n",
    "import random\n",
    "\n",
    "#made from larger sample than the json files included\n",
    "csv_file_train = 'counts_What--from2021-08-31_to_2021-10-19.csv'\n",
    "rnd = random.randint(0, 10000)\n",
    "#rnd = 0\n",
    "alpha = 1\n",
    "C = .1\n",
    "print ('RND SEED:', rnd)\n",
    "\n",
    "#initial learning on split data\n",
    "scaler, X, y, X_train, X_test, y_train, y_test = p.setup_data_categorized(csv_file_train, rnd)\n",
    "logReg = p.log_regress(X_train, X_test, y_train, y_test,C=C)\n",
    "#nn = neural_net(X_train, X_test, y_train, y_test, alpha=alpha) #using sklearn\n",
    "\n",
    "#Then with that model, make predictions on the stocks listed in another file\n",
    "csv_file_predict = 'counts_What--from2021-10-20_to_2021-10-26.csv'\n",
    "tickers = p.get_tickers(csv_file_predict)\n",
    "scaler, X, y, X_train, X_test, y_train, y_test = p.setup_data_categorized(csv_file_predict, rnd, scaler=scaler)\n",
    "print('LOG PREDICTIONS FINAL')\n",
    "p.clf_predictions_8_cats(X, logReg, tickers, y=y, cutoff=0.55)\n",
    "#print('NET PREDICTIONS FINAL')\n",
    "#clf_predictions_8_cats(X, nn, tickers, y=y, cutoff=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d20793-3672-4fda-bf45-e517529ced5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Sequential(\n",
      "  (input_layer): Linear(in_features=1017, out_features=10000, bias=True)\n",
      "  (activation_input): ReLU()\n",
      "  (hidden_layer_1): Linear(in_features=10000, out_features=3000, bias=True)\n",
      "  (activation_1): ReLU()\n",
      "  (hidden_layer_2): Linear(in_features=3000, out_features=2000, bias=True)\n",
      "  (activation_2): ReLU()\n",
      "  (hidden_layer_3): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "  (activation_3): ReLU()\n",
      "  (hidden_layer_4): Linear(in_features=1000, out_features=500, bias=True)\n",
      "  (activation_4): ReLU()\n",
      "  (output): Linear(in_features=500, out_features=8, bias=True)\n",
      ")\n",
      "Epoch 0...\n",
      "Epoch 0: Train loss: 2.084 accuracy: 0.060, Test loss: 2.080 accuracy: 0.035\n",
      "Epoch 1: Train loss: 2.076 accuracy: 0.242, Test loss: 2.073 accuracy: 0.238\n",
      "Epoch 2: Train loss: 2.069 accuracy: 0.256, Test loss: 2.066 accuracy: 0.238\n",
      "Epoch 3: Train loss: 2.062 accuracy: 0.256, Test loss: 2.059 accuracy: 0.238\n",
      "Epoch 4: Train loss: 2.056 accuracy: 0.256, Test loss: 2.053 accuracy: 0.238\n",
      "Epoch 5: Train loss: 2.050 accuracy: 0.256, Test loss: 2.047 accuracy: 0.238\n",
      "Epoch 6: Train loss: 2.044 accuracy: 0.256, Test loss: 2.042 accuracy: 0.238\n",
      "Epoch 7: Train loss: 2.038 accuracy: 0.256, Test loss: 2.036 accuracy: 0.238\n",
      "Epoch 8: Train loss: 2.033 accuracy: 0.256, Test loss: 2.031 accuracy: 0.238\n",
      "Epoch 9: Train loss: 2.027 accuracy: 0.256, Test loss: 2.026 accuracy: 0.238\n",
      "Epoch 10...\n",
      "Epoch 10: Train loss: 2.022 accuracy: 0.256, Test loss: 2.021 accuracy: 0.238\n",
      "Epoch 11: Train loss: 2.017 accuracy: 0.256, Test loss: 2.016 accuracy: 0.238\n",
      "Epoch 12: Train loss: 2.013 accuracy: 0.256, Test loss: 2.012 accuracy: 0.238\n",
      "Epoch 13: Train loss: 2.008 accuracy: 0.256, Test loss: 2.008 accuracy: 0.238\n",
      "Epoch 14: Train loss: 2.004 accuracy: 0.256, Test loss: 2.004 accuracy: 0.238\n",
      "Epoch 15: Train loss: 2.000 accuracy: 0.256, Test loss: 2.000 accuracy: 0.238\n",
      "Epoch 16: Train loss: 1.996 accuracy: 0.256, Test loss: 1.996 accuracy: 0.238\n",
      "Epoch 17: Train loss: 1.992 accuracy: 0.256, Test loss: 1.992 accuracy: 0.238\n",
      "Epoch 18: Train loss: 1.989 accuracy: 0.256, Test loss: 1.989 accuracy: 0.238\n",
      "Epoch 19: Train loss: 1.985 accuracy: 0.256, Test loss: 1.985 accuracy: 0.238\n",
      "Training finished. Loss: 1.985414981842041 Accuracy: 0.23846153846153847\n"
     ]
    }
   ],
   "source": [
    "#Use custom Pytorch mlp neural net\n",
    "import torchMLP as mlp\n",
    "nn = mlp.batch_train(X_train, X_test, y_train, y_test, batch_size=64, epochs=20, lr=1e-2,\n",
    "                     hidden_layer_sizes=(10000,3000,2000,1000,500), verbose=True, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac298cf7-683e-4b90-8b64-b32fdcb79e23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
